{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7865c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re    \n",
    "import json\n",
    "\n",
    "def load_videos_from_json(filename):\n",
    "    with open(filename, \"r\") as jsonfile:\n",
    "        return json.load(jsonfile)\n",
    "\n",
    "def similarity_score(video1, video2):\n",
    "    title1_words = set(video1[\"title\"].lower().split())\n",
    "    author1_words = set(video1[\"author\"].lower().split())\n",
    "    title2_words = set(video2[\"title\"].lower().split())\n",
    "    author2_words = set(video2[\"author\"].lower().split())\n",
    "    intersection_title = title1_words.intersection(title2_words)\n",
    "    intersection_author = author1_words.intersection(author2_words)\n",
    "    similarity = len(intersection_title) + len(intersection_author)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43983ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=3GbytQbQyUA'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = ['angry','disgust','fear','happy','neutral', 'sad', 'surprise']\n",
    "emotions_input_dict = {\n",
    "    'angry':'https://www.youtube.com/watch?v=3GbytQbQyUA',\n",
    "    'disgust':'https://www.youtube.com/watch?v=fKopy74weus',\n",
    "    'fear': 'https://www.youtube.com/watch?v=mPhboJR0Llc',\n",
    "    'happy':'https://www.youtube.com/watch?v=X72C8RfsrgA',\n",
    "    'neutral':'https://www.youtube.com/watch?v=1kWxjmzHKFI',\n",
    "    'sad':'https://www.youtube.com/watch?v=3DvBpc1lUvg',\n",
    "    'surprise':'https://www.youtube.com/watch?v=tKB4jpf2S1Q'\n",
    "}\n",
    "emotions_input_dict['angry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96ec2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video(emotion, emotions_input_dict):\n",
    "    videos = load_videos_from_json(emotion+'.json')\n",
    "    input_video_url = emotions_input_dict[emotion]\n",
    "    return input_video_url, videos\n",
    "\n",
    "def recomend(emotion, emotions_input_dict):\n",
    "    filename = emotion + '.json'\n",
    "    videos = load_videos_from_json(filename)\n",
    "    \n",
    "    emotions_input_dict = {\n",
    "    'angry':'https://www.youtube.com/watch?v=3GbytQbQyUA',\n",
    "    'disgust':'https://www.youtube.com/watch?v=fKopy74weus',\n",
    "    'fear': 'https://www.youtube.com/watch?v=mPhboJR0Llc',\n",
    "    'happy':'https://www.youtube.com/watch?v=X72C8RfsrgA',\n",
    "    'neutral':'https://www.youtube.com/watch?v=1kWxjmzHKFI',\n",
    "    'sad':'https://www.youtube.com/watch?v=3DvBpc1lUvg',\n",
    "    'surprise':'https://www.youtube.com/watch?v=tKB4jpf2S1Q'\n",
    "}\n",
    "    input_video_url = emotions_input_dict[emotion]\n",
    "    similarities = {}\n",
    "    #print(videos)\n",
    "    for video in videos:\n",
    "        if (video['link'] == input_video_url):\n",
    "            \n",
    "            input_video_info = {\n",
    "                        \"link\": video[\"link\"],\n",
    "                        \"title\": video[\"title\"],\n",
    "                        \"author\": video[\"author\"],\n",
    "                        \"video_id\": video[\"video_id\"],\n",
    "                        }\n",
    "            break\n",
    "    for video in videos:\n",
    "        url = video['link']\n",
    "        video_info = {\n",
    "                        \"link\": video[\"link\"],\n",
    "                        \"title\": video[\"title\"],\n",
    "                        \"author\": video[\"author\"],\n",
    "                        \"video_id\": video[\"video_id\"],\n",
    "                        }\n",
    "        if url != input_video_url:\n",
    "            similarity = similarity_score(input_video_info, video_info)\n",
    "            similarities[url] = similarity\n",
    "    sorted_similarities = dict(sorted(similarities.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "    print(\"Top 5 recommendations:\")\n",
    "    i = 0\n",
    "    for video in videos:\n",
    "        if (i<5):\n",
    "            for j, (url, score) in enumerate(sorted_similarities.items()):\n",
    "                if(video['link'] == url):\n",
    "                    print(f\"{i+1}. {video['title']} (by {video['author']}) {video['link']}\")\n",
    "        else:\n",
    "            break\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16451bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0a860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:33: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_29148\\3266116303.py:33: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  json_file = \"E:\\emosense\\Emotion_Detection_CNN-main\\output.json\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def max_word_occurrence(json_file):\n",
    "    word_counts = {}\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        text = \"\"\n",
    "    if isinstance(data, str):\n",
    "        text = data\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            text += \" \" + str(item)\n",
    "    elif isinstance(data, dict): \n",
    "        for key, value in data.items():\n",
    "            text += \" \" + str(key) + \" \" + str(value)\n",
    "    words = text.lower().split()\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        \n",
    "    max_word = None\n",
    "    max_count = 0\n",
    "    for word, count in word_counts.items():\n",
    "        if count > max_count:\n",
    "            max_word = word\n",
    "            max_count = count\n",
    "    if max_word:\n",
    "        print(f\"Word '{max_word}' has the maximum occurrence of {max_count} in the JSON file.\")\n",
    "    else:\n",
    "        print(\"No words found in the JSON file.\")\n",
    "\n",
    "    return max_word\n",
    "\n",
    "json_file = \"E:\\emosense\\Emotion_Detection_CNN-main\\output.json\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35aa9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_29148\\3266116303.py:33: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  json_file = \"E:\\emosense\\Emotion_Detection_CNN-main\\output.json\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\emosense\\\\Emotion_Detection_CNN-main\\\\output.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmax_word_occurrence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangry\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      3\u001b[0m     recomend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangry\u001b[39m\u001b[38;5;124m'\u001b[39m, emotions_input_dict)\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mmax_word_occurrence\u001b[1;34m(json_file)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_word_occurrence\u001b[39m(json_file):\n\u001b[0;32m      4\u001b[0m     word_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\emosense\\\\Emotion_Detection_CNN-main\\\\output.json'"
     ]
    }
   ],
   "source": [
    "output = max_word_occurrence(json_file)\n",
    "if (output == 'angry'):\n",
    "    recomend('angry', emotions_input_dict)\n",
    "elif (output == 'disgust'):\n",
    "    recomend('disgust', emotions_input_dict)\n",
    "elif(output == 'fear'):\n",
    "    recomend('fear', emotions_input_dict)\n",
    "elif(output == 'happy'):\n",
    "    recomend('happy', emotions_input_dict)\n",
    "elif(output == 'neutral'):\n",
    "    recomend('neutral', emotions_input_dict)\n",
    "elif(output == 'sad'):\n",
    "    recomend('sad', emotions_input_dict)\n",
    "elif(output == 'surprise'):\n",
    "    recomend('surprise', emotions_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a5c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['link', 'title', 'author', 'video_id'])\n",
      "Top 5 recommendations:\n",
      "1. An Unexpected Apology, Charli D'Amelio Coronavirus Challenge, Last Minute Stimulus Problem Emerges (by Philip DeFranco)\n",
      "2. WWE Smackdown 2002 Triple H vs Kurt Angle Full Match HD (by WWE Mania)\n",
      "3. Life with Bundy l 20/20 l PART 1 (by ABC News)\n",
      "5. G for Gharidha | Coronavirus: Salute to Pakistan's doctors, nurses | 25 March 2020 (by AapNewsPK)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'neutral' + '.json'\n",
    "videos = load_videos_from_json(filename)\n",
    "input_video_url = 'https://www.youtube.com/watch?v=1kWxjmzHKFI'\n",
    "similarities = {}\n",
    "#print(videos)\n",
    "for video in videos:\n",
    "    if (video['link'] == input_video_url):\n",
    "        print(video.keys())\n",
    "        input_video_info = {\n",
    "                    \"link\": video[\"link\"],\n",
    "                    \"title\": video[\"title\"],\n",
    "                    \"author\": video[\"author\"],\n",
    "                    \"video_id\": video[\"video_id\"],\n",
    "                    }\n",
    "        break\n",
    "for video in videos:\n",
    "    url = video['link']\n",
    "    video_info = {\n",
    "                    \"link\": video[\"link\"],\n",
    "                    \"title\": video[\"title\"],\n",
    "                    \"author\": video[\"author\"],\n",
    "                    \"video_id\": video[\"video_id\"],\n",
    "                    }\n",
    "    if url != input_video_url:\n",
    "        similarity = similarity_score(input_video_info, video_info)\n",
    "        similarities[url] = similarity\n",
    "sorted_similarities = dict(sorted(similarities.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "print(\"Top 5 recommendations:\")\n",
    "i = 0\n",
    "for video in videos:\n",
    "    if (i<5):\n",
    "        for j, (url, score) in enumerate(sorted_similarities.items()):\n",
    "            if(video['link'] == url):\n",
    "                print(f\"{i+1}. {video['title']} (by {video['author']})\")\n",
    "    else:\n",
    "        break\n",
    "    i+=1\n",
    "        \n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "link daalna\n",
    "all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1b00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_data = ['Sad', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy']\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json.dump(emotions_data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31076/3478621952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install cv2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mface_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\KIIT\\TTL\\New folder\\data\\Emotion_Detection_CNN-main\\haarcascade_frontalface_default.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\KIIT\\TTL\\New folder\\data\\Emotion_Detection_CNN-mainn\\model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "!pip install cv2\n",
    "import cv2\n",
    "face_classifier = cv2.CascadeClassifier(r'C:\\Users\\KIIT\\TTL\\New folder\\data\\Emotion_Detection_CNN-main\\haarcascade_frontalface_default.xml')\n",
    "classifier =load_model(r'C:\\Users\\KIIT\\TTL\\New folder\\data\\Emotion_Detection_CNN-mainn\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14825169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
